{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Project-2**\n",
    "\n",
    "In this project, you will analyze and predict the weekly sales for a retail store. The dataset includes weekly sales data for *45* store locations over a *143-week* period. Create a machine learning model (**regression**) to predict weekly sales values using the train and test datasets provided.\n",
    "\n",
    "**Dataset Details:**\n",
    "\n",
    "*Store*: Store number\n",
    "\n",
    "*Week*: 1 through 143\n",
    "\n",
    "*Temperature*: Weekly outside temperature\n",
    "\n",
    "*Holiday*: Yes for holiday week, No for non-holiday week\n",
    "\n",
    "*CPI*: The Consumer Price Index\n",
    "\n",
    "*Fuel Price*: Price per gallon\n",
    "\n",
    "*Unemployment*: Unemployment rate\n",
    "\n",
    "*WeeklySales*: Total sales amount\n",
    "\n",
    "\n",
    "**Datasets Locations and Names:**\n",
    "Canvas -> Modules -> Week 5 -> Datasets -> \"trainSales.csv\" and \"testSales.csv\".\n",
    "\n",
    "Download the .ipynb file and save as FirstName_LastName_Project2.ipynb. Please submit (upload) your source code to Canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "salesTrain = pd.read_csv(\"trainSales.csv\")\n",
    "salesTest = pd.read_csv(\"testSales.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = salesTrain.drop(columns=['WeeklySales'])\n",
    "y = salesTrain['WeeklySales'].copy()\n",
    "\n",
    "cat_feat = ['Holiday', 'Store']\n",
    "#num_feat = ['Week', 'Temperature', 'CPI', 'FuelPrice', 'Unemployment', 'Store']\n",
    "num_feat = [ 'CPI', 'FuelPrice',  'Unemployment']\n",
    "minmax_feat =['Week', 'Temperature',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Store  Week  Temperature Holiday         CPI  FuelPrice  Unemployment\n",
      "0        41    19        63.36      No  189.400073      2.684         7.363\n",
      "1        42    71        84.57      No  129.035710      3.981         8.494\n",
      "2         6    60        70.83      No  216.143816      3.473         6.858\n",
      "3        38   137        83.64      No  130.977667      4.133        10.926\n",
      "4        36    27        85.49      No  210.261493      2.573         8.360\n",
      "...     ...   ...          ...     ...         ...        ...           ...\n",
      "1282     26     1         9.55      No  131.527903      2.788         8.488\n",
      "1283     22   116        58.81      No  141.901526      4.046         7.671\n",
      "1284     21   126        88.05      No  221.481334      3.286         6.891\n",
      "1285     14    90        59.60      No  187.784620      3.570         8.523\n",
      "1286     17   113        45.29      No  130.967097      3.734         6.403\n",
      "\n",
      "[1287 rows x 7 columns]\n",
      "      Store  Week  Temperature Holiday         CPI  FuelPrice  Unemployment\n",
      "0         8   109        50.95      No  224.395979      3.630         5.825\n",
      "1         2   127        84.20      No  221.521506      3.227         6.565\n",
      "2        38    72        86.84      No  129.043200      3.935        13.736\n",
      "3        41    27        69.21      No  190.099003      2.690         7.335\n",
      "4        35   125        73.23      No  142.160646      3.564         8.876\n",
      "...     ...   ...          ...     ...         ...        ...           ...\n",
      "1282     26     1         9.55      No  131.527903      2.788         8.488\n",
      "1283     22   116        58.81      No  141.901526      4.046         7.671\n",
      "1284     21   126        88.05      No  221.481334      3.286         6.891\n",
      "1285     14    90        59.60      No  187.784620      3.570         8.523\n",
      "1286     17   113        45.29      No  130.967097      3.734         6.403\n",
      "\n",
      "[6435 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x2 = salesTest.drop(columns=['WeeklySales'])\n",
    "print(x2)\n",
    "y2 = salesTest['WeeklySales'].copy()\n",
    "\n",
    "X3 = pd.concat([X, x2])\n",
    "y3 = pd.concat([y, y2])\n",
    "\n",
    "print(X3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "cat_trans = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "                        ])\n",
    "\n",
    "num_trans = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "minmax_trans = Pipeline([\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "prepross = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_trans, num_feat),\n",
    "        ('cat', cat_trans, cat_feat),\n",
    "        ('minmax', minmax_trans, minmax_feat)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', prepross),\n",
    "    ('model', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "continuous is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\super\\Documents\\GitHub\\machine-learning-projects\\project2\\Gabriel_Lopez_Project2.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/super/Documents/GitHub/machine-learning-projects/project2/Gabriel_Lopez_Project2.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m mae \u001b[39m=\u001b[39m mean_absolute_error(y_test, y_pred)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/super/Documents/GitHub/machine-learning-projects/project2/Gabriel_Lopez_Project2.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# f1Score = f1_score(y_test, y_pred)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/super/Documents/GitHub/machine-learning-projects/project2/Gabriel_Lopez_Project2.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m prec_score \u001b[39m=\u001b[39m precision_score(y_test, y_pred)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/super/Documents/GitHub/machine-learning-projects/project2/Gabriel_Lopez_Project2.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m re_score \u001b[39m=\u001b[39m recall_score(y_test, y_pred)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/super/Documents/GitHub/machine-learning-projects/project2/Gabriel_Lopez_Project2.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m ac_score \u001b[39m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:2127\u001b[0m, in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1970\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[0;32m   1971\u001b[0m     {\n\u001b[0;32m   1972\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msparse matrix\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1996\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1997\u001b[0m ):\n\u001b[0;32m   1998\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[0;32m   1999\u001b[0m \n\u001b[0;32m   2000\u001b[0m \u001b[39m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2125\u001b[0m \u001b[39m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[0;32m   2126\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2127\u001b[0m     p, _, _, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[0;32m   2128\u001b[0m         y_true,\n\u001b[0;32m   2129\u001b[0m         y_pred,\n\u001b[0;32m   2130\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   2131\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   2132\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   2133\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mprecision\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[0;32m   2134\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   2135\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   2136\u001b[0m     )\n\u001b[0;32m   2137\u001b[0m     \u001b[39mreturn\u001b[39;00m p\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m global_skip_validation \u001b[39m=\u001b[39m get_config()[\u001b[39m\"\u001b[39m\u001b[39mskip_parameter_validation\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 184\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    186\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[0;32m    188\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1721\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1563\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[0;32m   1564\u001b[0m \n\u001b[0;32m   1565\u001b[0m \u001b[39mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1718\u001b[0m \u001b[39m array([2, 2, 2]))\u001b[39;00m\n\u001b[0;32m   1719\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m zero_division_value \u001b[39m=\u001b[39m _check_zero_division(zero_division)\n\u001b[1;32m-> 1721\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[0;32m   1723\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1724\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1499\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options \u001b[39mand\u001b[39;00m average \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1497\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(average_options))\n\u001b[1;32m-> 1499\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m   1500\u001b[0m \u001b[39m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m \u001b[39m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m present_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:104\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39m# No metrics support \"multiclass-multioutput\" format\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmultilabel-indicator\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m--> 104\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n\u001b[0;32m    106\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    107\u001b[0m     y_true \u001b[39m=\u001b[39m column_or_1d(y_true)\n",
      "\u001b[1;31mValueError\u001b[0m: continuous is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X3, y3, train_size=5148, shuffle=False)\n",
    "\n",
    "pipeline.fit(X_train,y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred) \n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "f1Score = f1_score(y_test, y_pred)\n",
    "prec_score = precision_score(y_test, y_pred)\n",
    "re_score = recall_score(y_test, y_pred)\n",
    "ac_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(X_train)\n",
    "print(X_test)\n",
    "print(mse)\n",
    "print(mae)\n",
    "print(r2)\n",
    "print(f1Score)\n",
    "print(prec_score)\n",
    "print(re_score)\n",
    "print(ac_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
